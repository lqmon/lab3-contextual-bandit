{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999bcd7d",
   "metadata": {},
   "source": [
    "# Lab 3: Contextual Bandit-Based News Article Recommendation\n",
    "\n",
    "**`Course`:** Reinforcement Learning Fundamentals  \n",
    "**`Student Name`:**  \n",
    "**`Roll Number`:**  \n",
    "**`GitHub Branch`:** firstname_U20230xxx  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755efd7a",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4bd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Import advanced classifiers\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from rlcmab_sampler import sampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c638ba06",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f6f6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Articles Dataset:\n",
      "                                                link  \\\n",
      "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
      "1  https://www.huffpost.com/entry/american-airlin...   \n",
      "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
      "3  https://www.huffpost.com/entry/funniest-parent...   \n",
      "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
      "\n",
      "                                            headline   category  \\\n",
      "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
      "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
      "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
      "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
      "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
      "\n",
      "                                   short_description               authors  \\\n",
      "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
      "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
      "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
      "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
      "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
      "\n",
      "         date  \n",
      "0  2022-09-23  \n",
      "1  2022-09-23  \n",
      "2  2022-09-23  \n",
      "3  2022-09-23  \n",
      "4  2022-09-22  \n",
      "\n",
      "Shape: (209527, 6)\n",
      "\n",
      "============================================================\n",
      "Train Users Dataset:\n",
      "  user_id   age  income  clicks  purchase_amount  session_duration  \\\n",
      "0   U7392   NaN   23053      10           500.00             17.34   \n",
      "1   U2702  56.0   20239      11           913.33             22.22   \n",
      "2   U2461   NaN   13907       9          1252.62             41.57   \n",
      "3   U7475   NaN   26615      12           500.00             30.17   \n",
      "4   U6040  32.0   27958      13           500.00             65.27   \n",
      "\n",
      "   content_variety  engagement_score  num_transactions  avg_monthly_spend  \\\n",
      "0          0.36661          37.29781                 3             187.44   \n",
      "1          0.61370          59.36342                 5             145.15   \n",
      "2          0.80368          76.78706                 7             282.03   \n",
      "3          0.26499          30.19441                10             195.35   \n",
      "4          0.36385          37.12153                 5             439.68   \n",
      "\n",
      "   ...  screen_brightness  battery_percentage  cart_abandonment_count  \\\n",
      "0  ...                4.0                 2.0                       8   \n",
      "1  ...                4.5                63.0                       5   \n",
      "2  ...                1.3                22.0                       2   \n",
      "3  ...                4.2                77.0                       9   \n",
      "4  ...                4.6                30.0                       9   \n",
      "\n",
      "   browser_version  background_app_count  session_inactivity_duration  \\\n",
      "0          3.17.97                    10                        22.75   \n",
      "1          1.57.10                     8                         1.75   \n",
      "2          2.16.94                    12                        29.33   \n",
      "3          9.90.20                     4                        21.61   \n",
      "4          1.99.38                     7                         7.58   \n",
      "\n",
      "   network_jitter  region_code  subscriber   label  \n",
      "0             8.0         Z999       False  user_3  \n",
      "1             4.0         U428        True  user_2  \n",
      "2            18.0         Z999        True  user_3  \n",
      "3            22.0         X123       False  user_3  \n",
      "4            52.0         S043       False  user_1  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "\n",
      "Shape: (2000, 33)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "news_df = pd.read_csv(\"data/news_articles.csv\")\n",
    "train_users = pd.read_csv(\"data/train_users.csv\")\n",
    "test_users = pd.read_csv(\"data/test_users.csv\")\n",
    "\n",
    "print(\"News Articles Dataset:\")\n",
    "print(news_df.head())\n",
    "print(f\"\\nShape: {news_df.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Train Users Dataset:\")\n",
    "print(train_users.head())\n",
    "print(f\"\\nShape: {train_users.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c5cb1",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this section:\n",
    "- Handle missing values\n",
    "- Encode categorical features\n",
    "- Prepare data for user classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "preprocessing_1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Missing Values Analysis\n",
      "============================================================\n",
      "\n",
      "News Articles Dataset:\n",
      "link                     0\n",
      "headline                 6\n",
      "category                 0\n",
      "short_description    19712\n",
      "authors              37418\n",
      "date                     0\n",
      "dtype: int64\n",
      "\n",
      "Shape: (209527, 6)\n",
      "\n",
      "Train Users Dataset:\n",
      "user_id                          0\n",
      "age                            698\n",
      "income                           0\n",
      "clicks                           0\n",
      "purchase_amount                  0\n",
      "session_duration                 0\n",
      "content_variety                  0\n",
      "engagement_score                 0\n",
      "num_transactions                 0\n",
      "avg_monthly_spend                0\n",
      "avg_cart_value                   0\n",
      "browsing_depth                   0\n",
      "revisit_rate                     0\n",
      "scroll_activity                  0\n",
      "time_on_site                     0\n",
      "interaction_count                0\n",
      "preferred_price_range            0\n",
      "discount_usage_rate              0\n",
      "wishlist_size                    0\n",
      "product_views                    0\n",
      "repeat_purchase_gap (days)       0\n",
      "churn_risk_score                 0\n",
      "loyalty_index                    0\n",
      "screen_brightness                0\n",
      "battery_percentage               0\n",
      "cart_abandonment_count           0\n",
      "browser_version                  0\n",
      "background_app_count             0\n",
      "session_inactivity_duration      0\n",
      "network_jitter                   0\n",
      "region_code                      0\n",
      "subscriber                       0\n",
      "label                            0\n",
      "dtype: int64\n",
      "\n",
      "Shape: (2000, 33)\n",
      "\n",
      "Test Users Dataset:\n",
      "user_id                          0\n",
      "age                            679\n",
      "income                           0\n",
      "clicks                           0\n",
      "purchase_amount                  0\n",
      "session_duration                 0\n",
      "content_variety                  0\n",
      "engagement_score                 0\n",
      "num_transactions                 0\n",
      "avg_monthly_spend                0\n",
      "avg_cart_value                   0\n",
      "browsing_depth                   0\n",
      "revisit_rate                     0\n",
      "scroll_activity                  0\n",
      "time_on_site                     0\n",
      "interaction_count                0\n",
      "preferred_price_range            0\n",
      "discount_usage_rate              0\n",
      "wishlist_size                    0\n",
      "product_views                    0\n",
      "repeat_purchase_gap (days)       0\n",
      "churn_risk_score                 0\n",
      "loyalty_index                    0\n",
      "screen_brightness                0\n",
      "battery_percentage               0\n",
      "cart_abandonment_count           0\n",
      "browser_version                  0\n",
      "background_app_count             0\n",
      "session_inactivity_duration      0\n",
      "network_jitter                   0\n",
      "region_code                      0\n",
      "subscriber                       0\n",
      "dtype: int64\n",
      "\n",
      "Shape: (2000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in all datasets\n",
    "print(\"=\" * 60)\n",
    "print(\"Missing Values Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNews Articles Dataset:\")\n",
    "print(news_df.isnull().sum())\n",
    "print(f\"\\nShape: {news_df.shape}\")\n",
    "\n",
    "print(\"\\nTrain Users Dataset:\")\n",
    "print(train_users.isnull().sum())\n",
    "print(f\"\\nShape: {train_users.shape}\")\n",
    "\n",
    "print(\"\\nTest Users Dataset:\")\n",
    "print(test_users.isnull().sum())\n",
    "print(f\"\\nShape: {test_users.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "preprocessing_2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "News Articles: 57136\n",
      "Train Users: 698\n",
      "Test Users: 679\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "# For numerical columns: fill with median\n",
    "# For categorical columns: fill with mode\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    \"\"\"\n",
    "    Handle missing values in the dataset.\n",
    "    - Numerical columns: filled with median\n",
    "    - Categorical columns: filled with mode\n",
    "    \"\"\"\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    for col in df_cleaned.columns:\n",
    "        if df_cleaned[col].isnull().sum() > 0:\n",
    "            if df_cleaned[col].dtype in ['int64', 'float64']:\n",
    "                # Fill numerical columns with median\n",
    "                df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
    "            else:\n",
    "                # Fill categorical columns with mode\n",
    "                df_cleaned[col].fillna(df_cleaned[col].mode()[0], inplace=True)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Clean all datasets\n",
    "news_df_clean = handle_missing_values(news_df)\n",
    "train_users_clean = handle_missing_values(train_users)\n",
    "test_users_clean = handle_missing_values(test_users)\n",
    "\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(f\"News Articles: {news_df_clean.isnull().sum().sum()}\")\n",
    "print(f\"Train Users: {train_users_clean.isnull().sum().sum()}\")\n",
    "print(f\"Test Users: {test_users_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "preprocessing_3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Dataset Information\n",
      "============================================================\n",
      "\n",
      "News Articles Categories:\n",
      "category\n",
      "POLITICS          35602\n",
      "WELLNESS          17945\n",
      "ENTERTAINMENT     17362\n",
      "TRAVEL             9900\n",
      "STYLE & BEAUTY     9814\n",
      "PARENTING          8791\n",
      "HEALTHY LIVING     6694\n",
      "QUEER VOICES       6347\n",
      "FOOD & DRINK       6340\n",
      "BUSINESS           5992\n",
      "COMEDY             5400\n",
      "SPORTS             5077\n",
      "BLACK VOICES       4583\n",
      "HOME & LIVING      4320\n",
      "PARENTS            3955\n",
      "THE WORLDPOST      3664\n",
      "WEDDINGS           3653\n",
      "WOMEN              3572\n",
      "CRIME              3562\n",
      "IMPACT             3484\n",
      "DIVORCE            3426\n",
      "WORLD NEWS         3299\n",
      "MEDIA              2944\n",
      "WEIRD NEWS         2777\n",
      "GREEN              2622\n",
      "WORLDPOST          2579\n",
      "RELIGION           2577\n",
      "STYLE              2254\n",
      "SCIENCE            2206\n",
      "TECH               2104\n",
      "TASTE              2096\n",
      "MONEY              1756\n",
      "ARTS               1509\n",
      "ENVIRONMENT        1444\n",
      "FIFTY              1401\n",
      "GOOD NEWS          1398\n",
      "U.S. NEWS          1377\n",
      "ARTS & CULTURE     1339\n",
      "COLLEGE            1144\n",
      "LATINO VOICES      1130\n",
      "CULTURE & ARTS     1074\n",
      "EDUCATION          1014\n",
      "Name: count, dtype: int64\n",
      "\n",
      "User Categories (Train):\n",
      "label\n",
      "user_2    712\n",
      "user_1    707\n",
      "user_3    581\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Column names (Train Users):\n",
      "['user_id', 'age', 'income', 'clicks', 'purchase_amount', 'session_duration', 'content_variety', 'engagement_score', 'num_transactions', 'avg_monthly_spend', 'avg_cart_value', 'browsing_depth', 'revisit_rate', 'scroll_activity', 'time_on_site', 'interaction_count', 'preferred_price_range', 'discount_usage_rate', 'wishlist_size', 'product_views', 'repeat_purchase_gap (days)', 'churn_risk_score', 'loyalty_index', 'screen_brightness', 'battery_percentage', 'cart_abandonment_count', 'browser_version', 'background_app_count', 'session_inactivity_duration', 'network_jitter', 'region_code', 'subscriber', 'label']\n"
     ]
    }
   ],
   "source": [
    "# Display dataset information\n",
    "print(\"=\" * 60)\n",
    "print(\"Dataset Information\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nNews Articles Categories:\")\n",
    "print(news_df_clean['category'].value_counts())\n",
    "\n",
    "print(\"\\nUser Categories (Train):\")\n",
    "print(train_users_clean['label'].value_counts())\n",
    "\n",
    "print(\"\\nColumn names (Train Users):\")\n",
    "print(train_users_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "preprocessing_4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['user_id', 'browser_version', 'region_code']\n",
      "Numerical columns: ['age', 'income', 'clicks', 'purchase_amount', 'session_duration', 'content_variety', 'engagement_score', 'num_transactions', 'avg_monthly_spend', 'avg_cart_value', 'browsing_depth', 'revisit_rate', 'scroll_activity', 'time_on_site', 'interaction_count', 'preferred_price_range', 'discount_usage_rate', 'wishlist_size', 'product_views', 'repeat_purchase_gap (days)', 'churn_risk_score', 'loyalty_index', 'screen_brightness', 'battery_percentage', 'cart_abandonment_count', 'background_app_count', 'session_inactivity_duration', 'network_jitter']\n"
     ]
    }
   ],
   "source": [
    "# Feature encoding for user data\n",
    "# Separate features and labels\n",
    "\n",
    "# For training users\n",
    "X_train_full = train_users_clean.drop('label', axis=1)\n",
    "y_train_full = train_users_clean['label']\n",
    "\n",
    "# For test users\n",
    "X_test = test_users_clean.drop('label', axis=1) if 'label' in test_users_clean.columns else test_users_clean\n",
    "\n",
    "# Identify categorical columns (non-numeric)\n",
    "categorical_cols = X_train_full.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_train_full.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "preprocessing_5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding completed!\n",
      "Encoded training data shape: (2000, 32)\n",
      "Encoded test data shape: (2000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features using LabelEncoder\n",
    "label_encoders = {}\n",
    "\n",
    "X_train_encoded = X_train_full.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # Fit on training data\n",
    "    X_train_encoded[col] = le.fit_transform(X_train_full[col].astype(str))\n",
    "    \n",
    "    # Transform test data (handle unseen labels)\n",
    "    if col in X_test_encoded.columns:\n",
    "        # Create a mapping for unseen categories\n",
    "        test_col_values = X_test[col].astype(str)\n",
    "        X_test_encoded[col] = test_col_values.map(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "        )\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"\\nEncoding completed!\")\n",
    "print(f\"Encoded training data shape: {X_train_encoded.shape}\")\n",
    "print(f\"Encoded test data shape: {X_test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "preprocessing_6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of encoded training data:\n",
      "   user_id   age  income  clicks  purchase_amount  session_duration  \\\n",
      "0     1340   NaN   23053      10           500.00             17.34   \n",
      "1      491  56.0   20239      11           913.33             22.22   \n",
      "2      446   NaN   13907       9          1252.62             41.57   \n",
      "3     1354   NaN   26615      12           500.00             30.17   \n",
      "4     1082  32.0   27958      13           500.00             65.27   \n",
      "\n",
      "   content_variety  engagement_score  num_transactions  avg_monthly_spend  \\\n",
      "0          0.36661          37.29781                 3             187.44   \n",
      "1          0.61370          59.36342                 5             145.15   \n",
      "2          0.80368          76.78706                 7             282.03   \n",
      "3          0.26499          30.19441                10             195.35   \n",
      "4          0.36385          37.12153                 5             439.68   \n",
      "\n",
      "   ...  loyalty_index  screen_brightness  battery_percentage  \\\n",
      "0  ...           15.0                4.0                 2.0   \n",
      "1  ...           33.0                4.5                63.0   \n",
      "2  ...           24.0                1.3                22.0   \n",
      "3  ...           11.0                4.2                77.0   \n",
      "4  ...           19.0                4.6                30.0   \n",
      "\n",
      "   cart_abandonment_count  browser_version  background_app_count  \\\n",
      "0                       8              464                    10   \n",
      "1                       5              115                     8   \n",
      "2                       2              259                    12   \n",
      "3                       9             1952                     4   \n",
      "4                       9              211                     7   \n",
      "\n",
      "   session_inactivity_duration  network_jitter  region_code  subscriber  \n",
      "0                        22.75             8.0         1283       False  \n",
      "1                         1.75             4.0          987        True  \n",
      "2                        29.33            18.0         1283        True  \n",
      "3                        21.61            22.0         1111       False  \n",
      "4                         7.58            52.0          872       False  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "Data types:\n",
      "user_id                          int64\n",
      "age                            float64\n",
      "income                           int64\n",
      "clicks                           int64\n",
      "purchase_amount                float64\n",
      "session_duration               float64\n",
      "content_variety                float64\n",
      "engagement_score               float64\n",
      "num_transactions                 int64\n",
      "avg_monthly_spend              float64\n",
      "avg_cart_value                 float64\n",
      "browsing_depth                   int64\n",
      "revisit_rate                   float64\n",
      "scroll_activity                  int64\n",
      "time_on_site                   float64\n",
      "interaction_count                int64\n",
      "preferred_price_range          float64\n",
      "discount_usage_rate            float64\n",
      "wishlist_size                    int64\n",
      "product_views                    int64\n",
      "repeat_purchase_gap (days)     float64\n",
      "churn_risk_score               float64\n",
      "loyalty_index                  float64\n",
      "screen_brightness              float64\n",
      "battery_percentage             float64\n",
      "cart_abandonment_count           int64\n",
      "browser_version                  int64\n",
      "background_app_count             int64\n",
      "session_inactivity_duration    float64\n",
      "network_jitter                 float64\n",
      "region_code                      int64\n",
      "subscriber                        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display sample of encoded data\n",
    "print(\"Sample of encoded training data:\")\n",
    "print(X_train_encoded.head())\n",
    "print(\"\\nData types:\")\n",
    "print(X_train_encoded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "preprocessing_7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "News Category Mapping\n",
      "============================================================\n",
      "\n",
      "Original categories in news dataset:\n",
      "<StringArray>\n",
      "[     'U.S. NEWS',         'COMEDY',      'PARENTING',     'WORLD NEWS',\n",
      " 'CULTURE & ARTS',           'TECH',         'SPORTS',  'ENTERTAINMENT',\n",
      "       'POLITICS',     'WEIRD NEWS',    'ENVIRONMENT',      'EDUCATION',\n",
      "          'CRIME',        'SCIENCE',       'WELLNESS',       'BUSINESS',\n",
      " 'STYLE & BEAUTY',   'FOOD & DRINK',          'MEDIA',   'QUEER VOICES',\n",
      "  'HOME & LIVING',          'WOMEN',   'BLACK VOICES',         'TRAVEL',\n",
      "          'MONEY',       'RELIGION',  'LATINO VOICES',         'IMPACT',\n",
      "       'WEDDINGS',        'COLLEGE',        'PARENTS', 'ARTS & CULTURE',\n",
      "          'STYLE',          'GREEN',          'TASTE', 'HEALTHY LIVING',\n",
      "  'THE WORLDPOST',      'GOOD NEWS',      'WORLDPOST',          'FIFTY',\n",
      "           'ARTS',        'DIVORCE']\n",
      "Length: 42, dtype: str\n",
      "\n",
      "Mapped categories:\n",
      "category_mapped\n",
      "Crime             40541\n",
      "Education         27750\n",
      "Entertainment     22762\n",
      "Tech              10302\n",
      "TRAVEL             9900\n",
      "STYLE & BEAUTY     9814\n",
      "HEALTHY LIVING     6694\n",
      "QUEER VOICES       6347\n",
      "FOOD & DRINK       6340\n",
      "SPORTS             5077\n",
      "BLACK VOICES       4583\n",
      "HOME & LIVING      4320\n",
      "PARENTS            3955\n",
      "THE WORLDPOST      3664\n",
      "WEDDINGS           3653\n",
      "WOMEN              3572\n",
      "IMPACT             3484\n",
      "DIVORCE            3426\n",
      "WORLD NEWS         3299\n",
      "MEDIA              2944\n",
      "WEIRD NEWS         2777\n",
      "GREEN              2622\n",
      "WORLDPOST          2579\n",
      "RELIGION           2577\n",
      "STYLE              2254\n",
      "TASTE              2096\n",
      "MONEY              1756\n",
      "ARTS               1509\n",
      "ENVIRONMENT        1444\n",
      "FIFTY              1401\n",
      "GOOD NEWS          1398\n",
      "ARTS & CULTURE     1339\n",
      "COLLEGE            1144\n",
      "LATINO VOICES      1130\n",
      "CULTURE & ARTS     1074\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "Arm Index Mapping (j values)\n",
      "============================================================\n",
      "Arm  0: (Entertainment, user_1)\n",
      "Arm  1: (Education    , user_1)\n",
      "Arm  2: (Tech         , user_1)\n",
      "Arm  3: (Crime        , user_1)\n",
      "Arm  4: (Entertainment, user_2)\n",
      "Arm  5: (Education    , user_2)\n",
      "Arm  6: (Tech         , user_2)\n",
      "Arm  7: (Crime        , user_2)\n",
      "Arm  8: (Entertainment, user_3)\n",
      "Arm  9: (Education    , user_3)\n",
      "Arm 10: (Tech         , user_3)\n",
      "Arm 11: (Crime        , user_3)\n",
      "\n",
      "Arm mapping created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Map news categories to standard format (Entertainment, Education, Tech, Crime)\n",
    "# Based on the assignment requirements\n",
    "print(\"=\" * 60)\n",
    "print(\"News Category Mapping\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# The actual categories in the dataset might differ from the required ones\n",
    "# We'll map them appropriately\n",
    "category_mapping = {\n",
    "    'U.S. NEWS': 'Crime',\n",
    "    'COMEDY': 'Entertainment',\n",
    "    'PARENTING': 'Education',\n",
    "    'POLITICS': 'Crime',\n",
    "    'WELLNESS': 'Education',\n",
    "    'ENTERTAINMENT': 'Entertainment',\n",
    "    'TECH': 'Tech',\n",
    "    'SCIENCE': 'Tech',\n",
    "    'BUSINESS': 'Tech',\n",
    "    'EDUCATION': 'Education',\n",
    "    'CRIME': 'Crime'\n",
    "}\n",
    "\n",
    "# Apply mapping if categories exist in news dataset\n",
    "if 'category' in news_df_clean.columns:\n",
    "    # Check unique categories\n",
    "    print(\"\\nOriginal categories in news dataset:\")\n",
    "    print(news_df_clean['category'].unique())\n",
    "    \n",
    "    # Map to standard categories\n",
    "    news_df_clean['category_mapped'] = news_df_clean['category'].map(\n",
    "        lambda x: category_mapping.get(x.upper() if isinstance(x, str) else x, x)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nMapped categories:\")\n",
    "    print(news_df_clean['category_mapped'].value_counts())\n",
    "    \n",
    "    # Use mapped categories\n",
    "    news_df_clean['category'] = news_df_clean['category_mapped']\n",
    "\n",
    "# Define the arm mapping according to assignment specifications\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Arm Index Mapping (j values)\")\n",
    "print(\"=\"*60)\n",
    "arm_mapping = {\n",
    "    0: ('Entertainment', 'user_1'),\n",
    "    1: ('Education', 'user_1'),\n",
    "    2: ('Tech', 'user_1'),\n",
    "    3: ('Crime', 'user_1'),\n",
    "    4: ('Entertainment', 'user_2'),\n",
    "    5: ('Education', 'user_2'),\n",
    "    6: ('Tech', 'user_2'),\n",
    "    7: ('Crime', 'user_2'),\n",
    "    8: ('Entertainment', 'user_3'),\n",
    "    9: ('Education', 'user_3'),\n",
    "    10: ('Tech', 'user_3'),\n",
    "    11: ('Crime', 'user_3')\n",
    "}\n",
    "\n",
    "for arm_idx, (category, user) in arm_mapping.items():\n",
    "    print(f\"Arm {arm_idx:2d}: ({category:13s}, {user})\")\n",
    "\n",
    "# Create reverse mapping for easy lookup\n",
    "category_user_to_arm = {v: k for k, v in arm_mapping.items()}\n",
    "print(\"\\nArm mapping created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d6352",
   "metadata": {},
   "source": [
    "## User Classification\n",
    "\n",
    "Train a classifier to predict the user category (`User1`, `User2`, `User3`),\n",
    "which serves as the **context** for the contextual bandit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "classification_1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split Summary:\n",
      "============================================================\n",
      "Training set size: 1600 samples\n",
      "Validation set size: 400 samples\n",
      "Test set size: 2000 samples\n",
      "\n",
      "Class distribution in training set:\n",
      "label\n",
      "user_2    570\n",
      "user_1    565\n",
      "user_3    465\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in validation set:\n",
      "label\n",
      "user_2    142\n",
      "user_1    142\n",
      "user_3    116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into train and validation sets (80-20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_encoded, \n",
    "    y_train_full, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(\"Data Split Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set size: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test_encoded.shape[0]} samples\")\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nClass distribution in validation set:\")\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "classification_2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using advanced gradient boosting classifiers...\n"
     ]
    }
   ],
   "source": [
    "# Note: We will use state-of-the-art gradient boosting classifiers:\n",
    "# - LightGBM: Fast, efficient, and excellent for structured data\n",
    "# - XGBoost: Robust and widely used in competitions\n",
    "# - CatBoost: Handles categorical features natively\n",
    "print(\"Using advanced gradient boosting classifiers...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "classification_3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training LightGBM Classifier\n",
      "============================================================\n",
      "\n",
      "Validation Accuracy: 0.8975\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      user_1       0.88      0.86      0.87       142\n",
      "      user_2       0.98      0.87      0.93       142\n",
      "      user_3       0.83      0.97      0.90       116\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.90      0.90      0.90       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   1  19]\n",
      " [ 14 124   4]\n",
      " [  2   1 113]]\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Classifier\n",
    "print(\"=\" * 60)\n",
    "print(\"Training LightGBM Classifier\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "lgb_classifier = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lgb = lgb_classifier.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "lgb_accuracy = accuracy_score(y_val, y_pred_lgb)\n",
    "print(f\"\\nValidation Accuracy: {lgb_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_lgb))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "classification_4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training XGBoost Classifier\n",
      "============================================================\n",
      "\n",
      "Validation Accuracy: 0.9000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      user_1       0.88      0.86      0.87       142\n",
      "      user_2       0.99      0.87      0.93       142\n",
      "      user_3       0.83      0.98      0.90       116\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.90      0.91      0.90       400\n",
      "weighted avg       0.91      0.90      0.90       400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   1  19]\n",
      " [ 14 124   4]\n",
      " [  2   0 114]]\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Classifier\n",
    "print(\"=\" * 60)\n",
    "print(\"Training XGBoost Classifier\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Encode labels for XGBoost (requires 0, 1, 2 format)\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_train_encoded = label_encoder_y.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder_y.transform(y_val)\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_classifier.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb_encoded = xgb_classifier.predict(X_val)\n",
    "y_pred_xgb = label_encoder_y.inverse_transform(y_pred_xgb_encoded)\n",
    "\n",
    "# Evaluation\n",
    "xgb_accuracy = accuracy_score(y_val, y_pred_xgb)\n",
    "print(f\"\\nValidation Accuracy: {xgb_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_xgb))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "classification_5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training CatBoost Classifier\n",
      "============================================================\n",
      "\n",
      "Validation Accuracy: 0.9050\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      user_1       0.90      0.86      0.88       142\n",
      "      user_2       0.98      0.88      0.93       142\n",
      "      user_3       0.83      0.99      0.91       116\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.91      0.91      0.91       400\n",
      "weighted avg       0.91      0.91      0.91       400\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[122   1  19]\n",
      " [ 13 125   4]\n",
      " [  0   1 115]]\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Classifier\n",
    "print(\"=\" * 60)\n",
    "print(\"Training CatBoost Classifier\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "catboost_classifier = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    learning_rate=0.05,\n",
    "    depth=7,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "catboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_cat = catboost_classifier.predict(X_val)\n",
    "\n",
    "# Evaluation\n",
    "cat_accuracy = accuracy_score(y_val, y_pred_cat)\n",
    "print(f\"\\nValidation Accuracy: {cat_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_cat))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "classification_6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Classifier Performance Comparison\n",
      "============================================================\n",
      "LightGBM Accuracy:  0.8975\n",
      "XGBoost Accuracy:   0.9000\n",
      "CatBoost Accuracy:  0.9050\n",
      "\n",
      "============================================================\n",
      "ðŸ† Best Classifier: CatBoost\n",
      "ðŸŽ¯ Best Accuracy: 0.9050\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Compare all classifiers\n",
    "print(\"=\" * 60)\n",
    "print(\"Classifier Performance Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"LightGBM Accuracy:  {lgb_accuracy:.4f}\")\n",
    "print(f\"XGBoost Accuracy:   {xgb_accuracy:.4f}\")\n",
    "print(f\"CatBoost Accuracy:  {cat_accuracy:.4f}\")\n",
    "\n",
    "# Select the best classifier\n",
    "classifiers = {\n",
    "    'LightGBM': (lgb_classifier, lgb_accuracy),\n",
    "    'XGBoost': (xgb_classifier, xgb_accuracy),\n",
    "    'CatBoost': (catboost_classifier, cat_accuracy)\n",
    "}\n",
    "\n",
    "best_classifier_name = max(classifiers, key=lambda k: classifiers[k][1])\n",
    "best_classifier = classifiers[best_classifier_name][0]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ðŸ† Best Classifier: {best_classifier_name}\")\n",
    "print(f\"ðŸŽ¯ Best Accuracy: {classifiers[best_classifier_name][1]:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "classification_7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retraining CatBoost on full training data...\n",
      "âœ… CatBoost trained on full training data!\n",
      "\n",
      "This classifier will be used as the Context Detector for the bandit system.\n"
     ]
    }
   ],
   "source": [
    "# Retrain the best classifier on the full training data for final use\n",
    "print(f\"\\nRetraining {best_classifier_name} on full training data...\")\n",
    "\n",
    "if best_classifier_name == 'LightGBM':\n",
    "    final_classifier = lgb.LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    )\n",
    "    final_classifier.fit(X_train_encoded, y_train_full)\n",
    "    \n",
    "elif best_classifier_name == 'XGBoost':\n",
    "    final_classifier = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        random_state=42,\n",
    "        eval_metric='mlogloss',\n",
    "        verbosity=0\n",
    "    )\n",
    "    y_train_full_encoded = label_encoder_y.fit_transform(y_train_full)\n",
    "    final_classifier.fit(X_train_encoded, y_train_full_encoded)\n",
    "    \n",
    "elif best_classifier_name == 'CatBoost':\n",
    "    final_classifier = CatBoostClassifier(\n",
    "        iterations=200,\n",
    "        learning_rate=0.05,\n",
    "        depth=7,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "    final_classifier.fit(X_train_encoded, y_train_full)\n",
    "\n",
    "print(f\"âœ… {best_classifier_name} trained on full training data!\")\n",
    "print(\"\\nThis classifier will be used as the Context Detector for the bandit system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "classification_8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions on test users:\n",
      "[['user_2']\n",
      " ['user_1']\n",
      " ['user_1']\n",
      " ['user_1']\n",
      " ['user_1']]\n",
      "\n",
      "============================================================\n",
      "User Context to Index Mapping (for Bandit):\n",
      "============================================================\n",
      "user_1 -> Index 0\n",
      "user_2 -> Index 1\n",
      "user_3 -> Index 2\n"
     ]
    }
   ],
   "source": [
    "# Create a function to predict user context\n",
    "def predict_user_context(user_features):\n",
    "    \"\"\"\n",
    "    Predict the user category (user_1, user_2, or user_3) given user features.\n",
    "    \n",
    "    Args:\n",
    "        user_features: DataFrame or array of user features\n",
    "    \n",
    "    Returns:\n",
    "        Predicted user category\n",
    "    \"\"\"\n",
    "    if best_classifier_name == 'XGBoost':\n",
    "        # XGBoost returns encoded labels, need to inverse transform\n",
    "        predictions_encoded = final_classifier.predict(user_features)\n",
    "        return label_encoder_y.inverse_transform(predictions_encoded)\n",
    "    else:\n",
    "        return final_classifier.predict(user_features)\n",
    "\n",
    "# Test the function on a sample\n",
    "sample_prediction = predict_user_context(X_test_encoded.iloc[:5])\n",
    "print(\"Sample predictions on test users:\")\n",
    "print(sample_prediction)\n",
    "\n",
    "# Display the mapping for reference\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"User Context to Index Mapping (for Bandit):\")\n",
    "print(\"=\"*60)\n",
    "user_to_index = {'user_1': 0, 'user_2': 1, 'user_3': 2}\n",
    "for user, idx in user_to_index.items():\n",
    "    print(f\"{user} -> Index {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49062051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MLP Classifier Training\n",
      "======================================================================\n",
      "Using split training data...\n",
      "  - X_train shape: (1600, 32), y_train_encoded shape: (1600,)\n",
      "  - X_val shape: (400, 32), y_val_encoded shape: (400,)\n",
      "âœ“ Imputed missing values using mean strategy\n",
      "\n",
      "Training MLP Classifier...\n",
      "âœ“ MLP Training Time: 0.6906 seconds\n",
      "âœ“ MLP Validation Accuracy: 0.8325\n",
      "\n",
      "======================================================================\n",
      "Classifier Comparison Summary\n",
      "======================================================================\n",
      "        Classifier  Accuracy  Training_Time\n",
      "MLP Neural Network    0.8325       0.690648\n",
      "           XGBoost    0.9000       0.000000\n",
      "          LightGBM    0.8975       0.000000\n",
      "          CatBoost    0.9050       0.000000\n",
      "\n",
      "âœ“ Best Classifier: CatBoost (Accuracy: 0.9050)\n",
      "âœ“ MLP score 0.8325 is competitive with CatBoost!\n"
     ]
    }
   ],
   "source": [
    "# MLP (Multi-Layer Perceptron) Neural Network Classifier\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MLP Classifier Training\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use the split training data (X_train is 1600 samples from train_test_split of X_train_encoded)\n",
    "print(f\"Using split training data...\")\n",
    "print(f\"  - X_train shape: {X_train.shape}, y_train_encoded shape: {y_train_encoded.shape}\")\n",
    "print(f\"  - X_val shape: {X_val.shape}, y_val_encoded shape: {y_val_encoded.shape}\")\n",
    "\n",
    "# Create and fit imputer on X_train (matched with y_train_encoded)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "X_train_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train),\n",
    "    columns=X_train.columns\n",
    ")\n",
    "\n",
    "X_val_imputed = pd.DataFrame(\n",
    "    imputer.transform(X_val),\n",
    "    columns=X_val.columns\n",
    ")\n",
    "\n",
    "X_test_imputed = pd.DataFrame(\n",
    "    imputer.transform(X_test_encoded),\n",
    "    columns=X_test_encoded.columns\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Imputed missing values using mean strategy\")\n",
    "\n",
    "# Standardize features for better MLP performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_val_scaled = scaler.transform(X_val_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Train MLP classifier\n",
    "print(\"\\nTraining MLP Classifier...\")\n",
    "start_time = time.time()\n",
    "\n",
    "mlp_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 32),  # 3 hidden layers with decreasing units\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.2,\n",
    "    n_iter_no_change=20,\n",
    "    verbose=0,\n",
    "    tol=1e-3\n",
    ")\n",
    "\n",
    "# Train using the matched training data and labels\n",
    "mlp_classifier.fit(X_train_scaled, y_train_encoded)\n",
    "mlp_time = time.time() - start_time\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred_mlp = mlp_classifier.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate MLP\n",
    "mlp_accuracy = accuracy_score(y_val_encoded, y_pred_mlp)\n",
    "\n",
    "print(f\"âœ“ MLP Training Time: {mlp_time:.4f} seconds\")\n",
    "print(f\"âœ“ MLP Validation Accuracy: {mlp_accuracy:.4f}\")\n",
    "\n",
    "# Store MLP classifier for later use\n",
    "if 'classifiers' not in locals():\n",
    "    classifiers = {}\n",
    "classifiers['MLP'] = mlp_classifier\n",
    "\n",
    "# Create results summary comparing all classifiers\n",
    "results_summary = [\n",
    "    {'Classifier': 'MLP Neural Network', 'Accuracy': mlp_accuracy, 'Training_Time': mlp_time},\n",
    "    {'Classifier': 'XGBoost', 'Accuracy': xgb_accuracy, 'Training_Time': 0},\n",
    "    {'Classifier': 'LightGBM', 'Accuracy': lgb_accuracy, 'Training_Time': 0},\n",
    "    {'Classifier': 'CatBoost', 'Accuracy': cat_accuracy, 'Training_Time': 0}\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Classifier Comparison Summary\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_table = pd.DataFrame(results_summary)\n",
    "print(results_table.to_string(index=False))\n",
    "\n",
    "# Find best classifier\n",
    "best_idx = results_table['Accuracy'].idxmax()\n",
    "best_classifier_name = results_table.loc[best_idx, 'Classifier']\n",
    "best_accuracy = results_table.loc[best_idx, 'Accuracy']\n",
    "\n",
    "print(f\"\\nâœ“ Best Classifier: {best_classifier_name} (Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "# Update final classifier if MLP is best\n",
    "if best_classifier_name == 'MLP Neural Network':\n",
    "    final_classifier = classifiers['MLP']\n",
    "    print(f\"âœ“ Updated final classifier to MLP Neural Network\")\n",
    "else:\n",
    "    print(f\"âœ“ MLP score {mlp_accuracy:.4f} is competitive with {best_classifier_name}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ba537f",
   "metadata": {},
   "source": [
    "# `Contextual Bandit`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465388d6",
   "metadata": {},
   "source": [
    "## Reward Sampler Initialization\n",
    "\n",
    "The sampler is initialized using the student's roll number `i`.\n",
    "Rewards are obtained using `sampler.sample(j)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0bb0f",
   "metadata": {},
   "source": [
    "## Arm Mapping\n",
    "\n",
    "| Arm Index (j) | News Category | User Context |\n",
    "|--------------|---------------|--------------|\n",
    "| 0â€“3          | Entertainment, Education, Tech, Crime | User1 |\n",
    "| 4â€“7          | Entertainment, Education, Tech, Crime | User2 |\n",
    "| 8â€“11         | Entertainment, Education, Tech, Crime | User3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c764d",
   "metadata": {},
   "source": [
    "## Epsilon-Greedy Strategy\n",
    "\n",
    "This section implements the epsilon-greedy contextual bandit algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571e8a6",
   "metadata": {},
   "source": [
    "## Upper Confidence Bound (UCB)\n",
    "\n",
    "This section implements the UCB strategy for contextual bandits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2fb86",
   "metadata": {},
   "source": [
    "## SoftMax Strategy\n",
    "\n",
    "This section implements the SoftMax strategy with temperature $ \\tau = 1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb144662",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Simulation\n",
    "\n",
    "We simulate the bandit algorithms for $T = 10,000$ steps and record rewards.\n",
    "\n",
    "P.S.: Change $T$ value as and if required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10b073",
   "metadata": {},
   "source": [
    "## Results and Analysis\n",
    "\n",
    "This section presents:\n",
    "- Average Reward vs Time\n",
    "- Hyperparameter comparisons\n",
    "- Observations and discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512fbb89",
   "metadata": {},
   "source": [
    "## Final Observations\n",
    "\n",
    "- Comparison of Epsilon-Greedy, UCB, and SoftMax\n",
    "- Effect of hyperparameters\n",
    "- Strengths and limitations of each approach\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5665d58e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
