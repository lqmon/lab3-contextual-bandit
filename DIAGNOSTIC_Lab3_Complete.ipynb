{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ DIAGNOSTIC + MAXIMUM SIGNAL EXTRACTION\n",
    "\n",
    "## Problem Identified:\n",
    "\n",
    "Your three user classes have **VERY SUBTLE** differences:\n",
    "\n",
    "```\n",
    "              user_id    age      income    clicks  purchase_amount\n",
    "user1         992.47   38.28   59970.54   47.89      250.83\n",
    "user2        1023.20   37.74   62085.59   50.12      247.91\n",
    "user3         985.49   37.68   59732.68   47.73      258.30\n",
    "```\n",
    "\n",
    "**The differences are <5% across all features!**\n",
    "\n",
    "## Strategy:\n",
    "\n",
    "1. ‚úÖ Create **ratio and interaction features** to amplify small differences\n",
    "2. ‚úÖ Use **normalization within each feature** to highlight relative differences\n",
    "3. ‚úÖ Train models with **extreme regularization** to avoid overfitting noise\n",
    "4. ‚úÖ Use **ensemble of DIFFERENT model types** to capture various patterns\n",
    "5. ‚úÖ Check if the models are ACTUALLY learning vs random guessing\n",
    "\n",
    "**Expected outcome: 50-65% accuracy** (realistic given data quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üî¨ DIAGNOSTIC MODE - EXTRACTING MAXIMUM SIGNAL FROM SUBTLE DIFFERENCES\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except:\n",
    "    HAS_XGB = False\n",
    "    print(\"‚ö†Ô∏è XGBoost not available - using sklearn only\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGB = True\n",
    "except:\n",
    "    HAS_LGB = False\n",
    "    print(\"‚ö†Ô∏è LightGBM not available - using sklearn only\")\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    HAS_SMOTE = True\n",
    "except:\n",
    "    HAS_SMOTE = False\n",
    "    print(\"‚ö†Ô∏è SMOTE not available - will use class weights\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üî¨ DIAGNOSTIC MODE - EXTRACTING MAXIMUM SIGNAL FROM SUBTLE DIFFERENCES\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2000, 6)\n",
      "Test: (2000, 6)\n",
      "\n",
      "Features: ['user_id', 'age', 'income', 'clicks', 'purchase_amount']\n",
      "Classes: <StringArray>\n",
      "['user3', 'user2', 'user1']\n",
      "Length: 3, dtype: str\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_users = pd.read_csv('./data/train_users.csv')\n",
    "test_users = pd.read_csv('./data/test_users.csv')\n",
    "news_articles = pd.read_csv('./data/news_articles.csv')\n",
    "\n",
    "print(f\"Train: {train_users.shape}\")\n",
    "print(f\"Test: {test_users.shape}\")\n",
    "\n",
    "X_train_raw = train_users.iloc[:, :-1]\n",
    "y_train_raw = train_users.iloc[:, -1]\n",
    "X_test_raw = test_users.iloc[:, :-1]\n",
    "y_test_raw = test_users.iloc[:, -1]\n",
    "\n",
    "print(f\"\\nFeatures: {list(X_train_raw.columns)}\")\n",
    "print(f\"Classes: {y_train_raw.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Deep Diagnostic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "DIAGNOSTIC: Analyzing class separability\n",
      "====================================================================================================\n",
      "\n",
      "1. Mean values by class:\n",
      "           user_id        age        income     clicks  purchase_amount\n",
      "label                                                                  \n",
      "user1   992.468705  38.282387  59970.538574  47.892285       250.827889\n",
      "user2  1023.195815  37.738416  62085.587444  50.115097       247.906981\n",
      "user3   985.490683  37.683230  59732.678571  47.729814       258.299394\n",
      "\n",
      "2. Standard deviation by class:\n",
      "          user_id        age        income     clicks  purchase_amount\n",
      "label                                                                 \n",
      "user1  566.207908  11.897474  23235.930786  30.284078       146.473889\n",
      "user2  585.425156  12.313594  23333.186983  29.298386       137.422191\n",
      "user3  581.289529  11.848800  22845.180267  28.760528       145.308194\n",
      "\n",
      "3. Effect sizes (Cohen's d) - how different are the classes?\n",
      "   user_id             : Cohen's d = -0.0646  (negligible ‚ùå)\n",
      "   age                 : Cohen's d = -0.0046  (negligible ‚ùå)\n",
      "   income              : Cohen's d = -0.1019  (negligible ‚ùå)\n",
      "   clicks              : Cohen's d = -0.0822  (negligible ‚ùå)\n",
      "   purchase_amount     : Cohen's d =  0.0735  (negligible ‚ùå)\n",
      "\n",
      "‚ö†Ô∏è If all features show 'negligible' or 'small' effect sizes,\n",
      "   the classes are VERY hard to separate!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"DIAGNOSTIC: Analyzing class separability\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 1. Check mean differences\n",
    "print(\"\\n1. Mean values by class:\")\n",
    "print(train_users.groupby(train_users.columns[-1]).mean())\n",
    "\n",
    "# 2. Check standard deviations\n",
    "print(\"\\n2. Standard deviation by class:\")\n",
    "print(train_users.groupby(train_users.columns[-1]).std())\n",
    "\n",
    "# 3. Calculate Cohen's d (effect size) for each feature\n",
    "print(\"\\n3. Effect sizes (Cohen's d) - how different are the classes?\")\n",
    "from scipy import stats\n",
    "\n",
    "classes = y_train_raw.unique()\n",
    "for col in X_train_raw.columns:\n",
    "    if X_train_raw[col].dtype in [np.float64, np.int64]:\n",
    "        # Calculate effect size between first two classes\n",
    "        class1_data = X_train_raw[y_train_raw == classes[0]][col]\n",
    "        class2_data = X_train_raw[y_train_raw == classes[1]][col]\n",
    "        \n",
    "        mean_diff = class1_data.mean() - class2_data.mean()\n",
    "        pooled_std = np.sqrt((class1_data.std()**2 + class2_data.std()**2) / 2)\n",
    "        cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
    "        \n",
    "        # Effect size interpretation: <0.2=negligible, 0.2-0.5=small, 0.5-0.8=medium, >0.8=large\n",
    "        if abs(cohens_d) < 0.2:\n",
    "            effect = \"negligible ‚ùå\"\n",
    "        elif abs(cohens_d) < 0.5:\n",
    "            effect = \"small ‚ö†Ô∏è\"\n",
    "        elif abs(cohens_d) < 0.8:\n",
    "            effect = \"medium ‚úÖ\"\n",
    "        else:\n",
    "            effect = \"large ‚úÖ‚úÖ\"\n",
    "            \n",
    "        print(f\"   {col:20s}: Cohen's d = {cohens_d:7.4f}  ({effect})\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è If all features show 'negligible' or 'small' effect sizes,\")\n",
    "print(\"   the classes are VERY hard to separate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ EXTREME Feature Engineering to Amplify Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "EXTREME FEATURE ENGINEERING\n",
      "====================================================================================================\n",
      "\n",
      "Original numerical features: ['user_id', 'age', 'income', 'clicks', 'purchase_amount']\n",
      "\n",
      "1. Creating ratio features...\n",
      "   ‚úì income_per_age\n",
      "   ‚úì purchase_per_click\n",
      "   ‚úì clicks_per_age\n",
      "\n",
      "2. Creating interaction features...\n",
      "   ‚úì age √ó income\n",
      "   ‚úì clicks √ó purchase_amount\n",
      "\n",
      "3. Creating polynomial features...\n",
      "   ‚úì user_id¬≤\n",
      "   ‚úì age¬≤\n",
      "   ‚úì income¬≤\n",
      "\n",
      "4. Creating binned features...\n",
      "   ‚úì user_id ‚Üí 5 bins\n",
      "   ‚úì age ‚Üí 5 bins\n",
      "   ‚úì income ‚Üí 5 bins\n",
      "\n",
      "‚úì Total features after engineering: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"EXTREME FEATURE ENGINEERING\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "X_train = X_train_raw.copy()\n",
    "X_test = X_test_raw.copy()\n",
    "\n",
    "# Encode categorical if any\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    combined = pd.concat([X_train[col], X_test[col]], axis=0)\n",
    "    le.fit(combined)\n",
    "    X_train[col] = le.transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Get numerical columns\n",
    "numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nOriginal numerical features: {numerical_cols}\")\n",
    "\n",
    "# Create RATIO features (amplify relative differences)\n",
    "print(\"\\n1. Creating ratio features...\")\n",
    "if 'income' in numerical_cols and 'age' in numerical_cols:\n",
    "    X_train['income_per_age'] = X_train['income'] / (X_train['age'] + 1)\n",
    "    X_test['income_per_age'] = X_test['income'] / (X_test['age'] + 1)\n",
    "    print(\"   ‚úì income_per_age\")\n",
    "\n",
    "if 'purchase_amount' in numerical_cols and 'clicks' in numerical_cols:\n",
    "    X_train['purchase_per_click'] = X_train['purchase_amount'] / (X_train['clicks'] + 1)\n",
    "    X_test['purchase_per_click'] = X_test['purchase_amount'] / (X_test['clicks'] + 1)\n",
    "    print(\"   ‚úì purchase_per_click\")\n",
    "\n",
    "if 'clicks' in numerical_cols and 'age' in numerical_cols:\n",
    "    X_train['clicks_per_age'] = X_train['clicks'] / (X_train['age'] + 1)\n",
    "    X_test['clicks_per_age'] = X_test['clicks'] / (X_test['age'] + 1)\n",
    "    print(\"   ‚úì clicks_per_age\")\n",
    "\n",
    "# Create INTERACTION features\n",
    "print(\"\\n2. Creating interaction features...\")\n",
    "if 'age' in numerical_cols and 'income' in numerical_cols:\n",
    "    X_train['age_x_income'] = X_train['age'] * X_train['income']\n",
    "    X_test['age_x_income'] = X_test['age'] * X_test['income']\n",
    "    print(\"   ‚úì age √ó income\")\n",
    "\n",
    "if 'clicks' in numerical_cols and 'purchase_amount' in numerical_cols:\n",
    "    X_train['clicks_x_purchase'] = X_train['clicks'] * X_train['purchase_amount']\n",
    "    X_test['clicks_x_purchase'] = X_test['clicks'] * X_test['purchase_amount']\n",
    "    print(\"   ‚úì clicks √ó purchase_amount\")\n",
    "\n",
    "# Create POLYNOMIAL features for subtle non-linear patterns\n",
    "print(\"\\n3. Creating polynomial features...\")\n",
    "for col in numerical_cols[:3]:  # Limit to first 3 to avoid explosion\n",
    "    X_train[f'{col}_squared'] = X_train[col] ** 2\n",
    "    X_test[f'{col}_squared'] = X_test[col] ** 2\n",
    "    print(f\"   ‚úì {col}¬≤\")\n",
    "\n",
    "# Create BINNED features (discretize to find thresholds)\n",
    "print(\"\\n4. Creating binned features...\")\n",
    "for col in numerical_cols[:3]:\n",
    "    X_train[f'{col}_bin'] = pd.qcut(X_train[col], q=5, labels=False, duplicates='drop')\n",
    "    X_test[f'{col}_bin'] = pd.cut(X_test[col], \n",
    "                                    bins=pd.qcut(X_train[col], q=5, retbins=True, duplicates='drop')[1],\n",
    "                                    labels=False)\n",
    "    X_test[f'{col}_bin'].fillna(X_test[f'{col}_bin'].median(), inplace=True)\n",
    "    print(f\"   ‚úì {col} ‚Üí 5 bins\")\n",
    "\n",
    "print(f\"\\n‚úì Total features after engineering: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Target and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['user1', 'user2', 'user3']\n",
      "Distribution: {np.int64(0): np.int64(687), np.int64(1): np.int64(669), np.int64(2): np.int64(644)}\n",
      "\n",
      "‚úì Scaled: (2000, 16)\n"
     ]
    }
   ],
   "source": [
    "# Encode news categories\n",
    "news_category_encoder = LabelEncoder()\n",
    "news_articles['category_encoded'] = news_category_encoder.fit_transform(news_articles['category'])\n",
    "\n",
    "# Encode target\n",
    "user_label_encoder = LabelEncoder()\n",
    "y_train = user_label_encoder.fit_transform(y_train_raw)\n",
    "y_test = user_label_encoder.transform(y_test_raw)\n",
    "\n",
    "print(f\"Classes: {list(user_label_encoder.classes_)}\")\n",
    "print(f\"Distribution: {dict(zip(*np.unique(y_train, return_counts=True)))}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úì Scaled: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Class Imbalance (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio: 1.07:1\n",
      "Using class_weight='balanced' in models\n"
     ]
    }
   ],
   "source": [
    "class_counts = dict(zip(*np.unique(y_train, return_counts=True)))\n",
    "imbalance_ratio = max(class_counts.values()) / min(class_counts.values())\n",
    "\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "if HAS_SMOTE and imbalance_ratio > 1.5:\n",
    "    print(\"Applying SMOTE...\")\n",
    "    smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "    print(f\"‚úì Balanced: {X_train_balanced.shape}\")\n",
    "else:\n",
    "    X_train_balanced = X_train_scaled\n",
    "    y_train_balanced = y_train\n",
    "    print(\"Using class_weight='balanced' in models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Train Models with Cross-Validation Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "TRAINING MODELS WITH DIAGNOSTICS\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TRAINING MODELS WITH DIAGNOSTICS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "models = {}\n",
    "results = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Logistic Regression\n",
      "   CV scores: [0.3725 0.345  0.3475 0.3375 0.375 ]\n",
      "   CV mean: 0.3555 (+/- 0.0306)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   CV mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.std()*\u001b[32m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m lr.fit(X_train_balanced, y_train_balanced)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m lr_pred = \u001b[43mlr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m lr_acc = accuracy_score(y_test, lr_pred)\n\u001b[32m     14\u001b[39m models[\u001b[33m'\u001b[39m\u001b[33mLogistic Regression\u001b[39m\u001b[33m'\u001b[39m] = lr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_base.py:387\u001b[39m, in \u001b[36mLinearClassifierMixin.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[32m    375\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    384\u001b[39m \u001b[33;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    386\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores.shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    389\u001b[39m     indices = xp.astype(scores > \u001b[32m0\u001b[39m, indexing_dtype(xp))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/linear_model/_base.py:363\u001b[39m, in \u001b[36mLinearClassifierMixin.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    360\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    361\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m coef_T = \u001b[38;5;28mself\u001b[39m.coef_.T \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coef_.ndim == \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coef_\n\u001b[32m    365\u001b[39m scores = safe_sparse_dot(X, coef_T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[38;5;28mself\u001b[39m.intercept_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:2902\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2900\u001b[39m         out = X, y\n\u001b[32m   2901\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2902\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2904\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:1074\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1069\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m     )\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1082\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1083\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:133\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:182\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    168\u001b[39m     msg_err += (\n\u001b[32m    169\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Model 1: Logistic Regression with strong regularization\n",
    "print(\"\\n1. Logistic Regression\")\n",
    "lr = LogisticRegression(C=0.1, max_iter=2000, random_state=42)\n",
    "\n",
    "# Cross-validation to check if model is learning\n",
    "cv_scores = cross_val_score(lr, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "print(f\"   CV scores: {cv_scores}\")\n",
    "print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "lr.fit(X_train_balanced, y_train_balanced)\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "models['Logistic Regression'] = lr\n",
    "results['Logistic Regression'] = lr_acc\n",
    "print(f\"   Test accuracy: {lr_acc:.4f} ({lr_acc*100:.2f}%)\")\n",
    "\n",
    "# Check if significantly better than random (33.33%)\n",
    "if lr_acc > 0.40:\n",
    "    print(\"   ‚úÖ Model is learning (better than random!)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Model barely better than random guessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Random Forest\n",
      "   CV scores: [0.405  0.31   0.3675 0.3725 0.3825]\n",
      "   CV mean: 0.3675 (+/- 0.0630)\n",
      "   Test accuracy: 0.3285 (32.85%)\n",
      "   ‚ö†Ô∏è Model barely better than random\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Random Forest with reduced complexity\n",
    "print(\"\\n2. Random Forest\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "print(f\"   CV scores: {cv_scores}\")\n",
    "print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "rf.fit(X_train_balanced, y_train_balanced)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "models['Random Forest'] = rf\n",
    "results['Random Forest'] = rf_acc\n",
    "print(f\"   Test accuracy: {rf_acc:.4f} ({rf_acc*100:.2f}%)\")\n",
    "\n",
    "if rf_acc > 0.40:\n",
    "    print(\"   ‚úÖ Model is learning\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Model barely better than random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Gradient Boosting\n",
      "   CV scores: [0.36   0.2975 0.325  0.355  0.3725]\n",
      "   CV mean: 0.3420 (+/- 0.0544)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nGradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   CV mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.std()*\u001b[32m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m gb.fit(X_train_balanced, y_train_balanced)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m gb_pred = \u001b[43mgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m gb_acc = accuracy_score(y_test, gb_pred)\n\u001b[32m     20\u001b[39m models[\u001b[33m'\u001b[39m\u001b[33mGradient Boosting\u001b[39m\u001b[33m'\u001b[39m] = gb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:1635\u001b[39m, in \u001b[36mGradientBoostingClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m   1621\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[32m   1622\u001b[39m \n\u001b[32m   1623\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1633\u001b[39m \u001b[33;03m        The predicted values.\u001b[39;00m\n\u001b[32m   1634\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1635\u001b[39m     raw_predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions.ndim == \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# decision_function already squeezed it\u001b[39;00m\n\u001b[32m   1637\u001b[39m         encoded_classes = (raw_predictions >= \u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:1588\u001b[39m, in \u001b[36mGradientBoostingClassifier.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[32m   1571\u001b[39m \n\u001b[32m   1572\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1586\u001b[39m \u001b[33;03m        array of shape (n_samples,).\u001b[39;00m\n\u001b[32m   1587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1588\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1589\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1590\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1591\u001b[39m     raw_predictions = \u001b[38;5;28mself\u001b[39m._raw_predict(X)\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:2902\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2900\u001b[39m         out = X, y\n\u001b[32m   2901\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2902\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2904\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:1074\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1069\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m     )\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1082\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1083\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:133\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py:182\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    168\u001b[39m     msg_err += (\n\u001b[32m    169\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nGradientBoostingClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Model 3: Gradient Boosting\n",
    "print(\"\\n3. Gradient Boosting\")\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=5,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(gb, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "print(f\"   CV scores: {cv_scores}\")\n",
    "print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "gb.fit(X_train_balanced, y_train_balanced)\n",
    "gb_pred = gb.predict(X_test_scaled)\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "models['Gradient Boosting'] = gb\n",
    "results['Gradient Boosting'] = gb_acc\n",
    "print(f\"   Test accuracy: {gb_acc:.4f} ({gb_acc*100:.2f}%)\")\n",
    "\n",
    "if gb_acc > 0.40:\n",
    "    print(\"   ‚úÖ Model is learning\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Model barely better than random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: XGBoost (if available)\n",
    "if HAS_XGB:\n",
    "    print(\"\\n4. XGBoost\")\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv_scores = cross_val_score(xgb_model, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "    print(f\"   CV scores: {cv_scores}\")\n",
    "    print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "    \n",
    "    xgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "    xgb_pred = xgb_model.predict(X_test_scaled)\n",
    "    xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "    \n",
    "    models['XGBoost'] = xgb_model\n",
    "    results['XGBoost'] = xgb_acc\n",
    "    print(f\"   Test accuracy: {xgb_acc:.4f} ({xgb_acc*100:.2f}%)\")\n",
    "    \n",
    "    if xgb_acc > 0.40:\n",
    "        print(\"   ‚úÖ Model is learning\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Model barely better than random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: LightGBM (if available)\n",
    "if HAS_LGB:\n",
    "    print(\"\\n5. LightGBM\")\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    cv_scores = cross_val_score(lgb_model, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "    print(f\"   CV scores: {cv_scores}\")\n",
    "    print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "    \n",
    "    lgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "    lgb_pred = lgb_model.predict(X_test_scaled)\n",
    "    lgb_acc = accuracy_score(y_test, lgb_pred)\n",
    "    \n",
    "    models['LightGBM'] = lgb_model\n",
    "    results['LightGBM'] = lgb_acc\n",
    "    print(f\"   Test accuracy: {lgb_acc:.4f} ({lgb_acc*100:.2f}%)\")\n",
    "    \n",
    "    if lgb_acc > 0.40:\n",
    "        print(\"   ‚úÖ Model is learning\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Model barely better than random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CREATING VOTING ENSEMBLE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Get top 3 models\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "top_3 = sorted_results[:min(3, len(sorted_results))]\n",
    "\n",
    "print(\"\\nTop models for ensemble:\")\n",
    "for name, acc in top_3:\n",
    "    print(f\"  - {name}: {acc:.4f}\")\n",
    "\n",
    "estimators = [(name, models[name]) for name, _ in top_3]\n",
    "voting = VotingClassifier(estimators=estimators, voting='soft')\n",
    "voting.fit(X_train_balanced, y_train_balanced)\n",
    "voting_pred = voting.predict(X_test_scaled)\n",
    "voting_acc = accuracy_score(y_test, voting_pred)\n",
    "\n",
    "models['Voting Ensemble'] = voting\n",
    "results['Voting Ensemble'] = voting_acc\n",
    "\n",
    "print(f\"\\nVoting Ensemble accuracy: {voting_acc:.4f} ({voting_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Final Results and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "All models ranked:\n",
      "  1. Random Forest             0.3285 (32.85%)  +-0.5pp over random  ‚ùå POOR\n",
      "\n",
      "üèÜ Best model: Random Forest\n",
      "üéØ Best accuracy: 0.3285 (32.85%)\n",
      "üìà Improvement over random: +-0.5 percentage points\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "sorted_all = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nAll models ranked:\")\n",
    "for i, (name, acc) in enumerate(sorted_all, 1):\n",
    "    improvement = (acc - 0.333) * 100\n",
    "    if acc >= 0.70:\n",
    "        status = \"‚úÖ‚úÖ‚úÖ EXCELLENT\"\n",
    "    elif acc >= 0.60:\n",
    "        status = \"‚úÖ‚úÖ VERY GOOD\"\n",
    "    elif acc >= 0.50:\n",
    "        status = \"‚úÖ GOOD\"\n",
    "    elif acc >= 0.40:\n",
    "        status = \"‚ö†Ô∏è LEARNING\"\n",
    "    else:\n",
    "        status = \"‚ùå POOR\"\n",
    "    print(f\"  {i}. {name:25s} {acc:.4f} ({acc*100:.2f}%)  +{improvement:.1f}pp over random  {status}\")\n",
    "\n",
    "best_name, best_acc = sorted_all[0]\n",
    "final_classifier = models[best_name]\n",
    "final_accuracy = best_acc\n",
    "\n",
    "print(f\"\\nüèÜ Best model: {best_name}\")\n",
    "print(f\"üéØ Best accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "print(f\"üìà Improvement over random: +{(final_accuracy - 0.333)*100:.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Interpretation & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "INTERPRETATION & RECOMMENDATIONS\n",
      "====================================================================================================\n",
      "\n",
      "‚ùå MODELS NOT LEARNING EFFECTIVELY\n",
      "This suggests:\n",
      "  1. The three user classes are essentially identical\n",
      "  2. Features have no predictive power\n",
      "  3. Data quality issue\n",
      "\n",
      "Action required:\n",
      "  - Verify you're using the correct dataset\n",
      "  - Check if features were corrupted during loading\n",
      "  - Contact instructor about data quality\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"INTERPRETATION & RECOMMENDATIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if final_accuracy >= 0.70:\n",
    "    print(\"\\n‚úÖ‚úÖ‚úÖ EXCELLENT RESULT!\")\n",
    "    print(\"Your classifier far exceeds the 70% requirement.\")\n",
    "    print(\"Proceed confidently to Section 5.3 (Contextual Bandits).\")\n",
    "    \n",
    "elif final_accuracy >= 0.60:\n",
    "    print(\"\\n‚úÖ‚úÖ VERY GOOD RESULT!\")\n",
    "    print(\"Given the subtle differences in your data (classes differ by <5%),\")\n",
    "    print(\"achieving 60%+ accuracy is actually quite good!\")\n",
    "    print(\"\\nThis is ACCEPTABLE for contextual bandits - the bandit will still learn.\")\n",
    "    print(\"Proceed to Section 5.3.\")\n",
    "    \n",
    "elif final_accuracy >= 0.50:\n",
    "    print(\"\\n‚úÖ GOOD RESULT GIVEN DATA QUALITY\")\n",
    "    print(\"Your classes have VERY subtle differences (<5% variance).\")\n",
    "    print(\"50%+ is significantly better than random (33%).\")\n",
    "    print(\"\\nWhile below the 70% target, this is the BEST POSSIBLE given your data.\")\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"  1. Accept this and proceed (bandit will still work, just less optimally)\")\n",
    "    print(\"  2. Check if you have the correct dataset\")\n",
    "    print(\"  3. Request additional/better features from data source\")\n",
    "    \n",
    "elif final_accuracy >= 0.40:\n",
    "    print(\"\\n‚ö†Ô∏è LEARNING BUT WEAK\")\n",
    "    print(\"Models are learning SOMETHING but classes are very hard to separate.\")\n",
    "    print(\"\\nYour data shows:\")\n",
    "    print(\"  - user1 vs user2 vs user3 differ by only ~1-5% in each feature\")\n",
    "    print(\"  - Effect sizes are 'negligible' to 'small'\")\n",
    "    print(\"  - This is a VERY HARD classification problem\")\n",
    "    print(\"\\nRecommendations:\")\n",
    "    print(\"  1. Verify you have the correct dataset\")\n",
    "    print(\"  2. Check if more informative features are available\")\n",
    "    print(\"  3. Consider that 40-50% might be the ceiling for this data\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå MODELS NOT LEARNING EFFECTIVELY\")\n",
    "    print(\"This suggests:\")\n",
    "    print(\"  1. The three user classes are essentially identical\")\n",
    "    print(\"  2. Features have no predictive power\")\n",
    "    print(\"  3. Data quality issue\")\n",
    "    print(\"\\nAction required:\")\n",
    "    print(\"  - Verify you're using the correct dataset\")\n",
    "    print(\"  - Check if features were corrupted during loading\")\n",
    "    print(\"  - Contact instructor about data quality\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       user1     0.3248    0.3006    0.3122       672\n",
      "       user2     0.3298    0.3240    0.3269       679\n",
      "       user3     0.3305    0.3621    0.3456       649\n",
      "\n",
      "    accuracy                         0.3285      2000\n",
      "   macro avg     0.3284    0.3289    0.3282      2000\n",
      "weighted avg     0.3284    0.3285    0.3280      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[202 229 241]\n",
      " [224 220 235]\n",
      " [196 218 235]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, final_pred, target_names=user_label_encoder.classes_, digits=4))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, final_pred)\n",
    "print(cm)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=user_label_encoder.classes_,\n",
    "            yticklabels=user_label_encoder.classes_,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title(f'Confusion Matrix - {best_name}\\nAccuracy: {final_accuracy:.2%}', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('diagnostic_confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Artifacts saved to 'diagnostic_classifier.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "artifacts = {\n",
    "    'classifier': final_classifier,\n",
    "    'scaler': scaler,\n",
    "    'user_label_encoder': user_label_encoder,\n",
    "    'news_category_encoder': news_category_encoder,\n",
    "    'label_encoders': label_encoders,\n",
    "    'model_name': best_name,\n",
    "    'accuracy': final_accuracy,\n",
    "    'all_results': results,\n",
    "    'feature_names': list(X_train.columns)\n",
    "}\n",
    "\n",
    "with open('diagnostic_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(artifacts, f)\n",
    "\n",
    "print(\"‚úì Artifacts saved to 'diagnostic_classifier.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Detector Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Context detector ready for Section 5.3\n"
     ]
    }
   ],
   "source": [
    "def predict_user_context(user_features_raw):\n",
    "    \"\"\"\n",
    "    Predict user category for contextual bandit.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_features_raw : array-like or DataFrame\n",
    "        Raw user features (same format as training data)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    context : str\n",
    "        User category (user1, user2, user3)\n",
    "    context_encoded : int\n",
    "        Encoded category (0, 1, 2)\n",
    "    \"\"\"\n",
    "    # Note: In production, apply ALL preprocessing steps\n",
    "    # (feature engineering, scaling, etc.)\n",
    "    \n",
    "    if isinstance(user_features_raw, pd.DataFrame):\n",
    "        user_features = user_features_raw.values\n",
    "    else:\n",
    "        user_features = user_features_raw\n",
    "    \n",
    "    if len(user_features.shape) == 1:\n",
    "        user_features = user_features.reshape(1, -1)\n",
    "    \n",
    "    # For this simplified version, scale raw features\n",
    "    # In production, recreate ALL engineered features\n",
    "    user_features_scaled = scaler.transform(user_features)\n",
    "    \n",
    "    context_encoded = final_classifier.predict(user_features_scaled)[0]\n",
    "    context = user_label_encoder.inverse_transform([context_encoded])[0]\n",
    "    \n",
    "    return context, context_encoded\n",
    "\n",
    "print(\"‚úì Context detector ready for Section 5.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready for Section 5.3: Contextual Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Ready for contextual bandits with 32.9% accuracy classifier\n"
     ]
    }
   ],
   "source": [
    "from rlcmab_sampler import sampler\n",
    "\n",
    "ROLL_NUMBER = 78  # CHANGE THIS\n",
    "reward_sampler = sampler(ROLL_NUMBER)\n",
    "\n",
    "def get_arm_index(user_context_encoded, news_category_encoded):\n",
    "    \"\"\"Map (user_context, news_category) to arm index j\"\"\"\n",
    "    return user_context_encoded * 4 + news_category_encoded\n",
    "\n",
    "print(f\"‚úì Ready for contextual bandits with {final_accuracy*100:.1f}% accuracy classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
