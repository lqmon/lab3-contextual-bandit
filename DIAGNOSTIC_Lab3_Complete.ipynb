{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ DIAGNOSTIC + MAXIMUM SIGNAL EXTRACTION\n",
    "\n",
    "## Problem Identified:\n",
    "\n",
    "Your three user classes have **VERY SUBTLE** differences:\n",
    "\n",
    "```\n",
    "              user_id    age      income    clicks  purchase_amount\n",
    "user1         992.47   38.28   59970.54   47.89      250.83\n",
    "user2        1023.20   37.74   62085.59   50.12      247.91\n",
    "user3         985.49   37.68   59732.68   47.73      258.30\n",
    "```\n",
    "\n",
    "**The differences are <5% across all features!**\n",
    "\n",
    "## Strategy:\n",
    "\n",
    "1. ‚úÖ Create **ratio and interaction features** to amplify small differences\n",
    "2. ‚úÖ Use **normalization within each feature** to highlight relative differences\n",
    "3. ‚úÖ Train models with **extreme regularization** to avoid overfitting noise\n",
    "4. ‚úÖ Use **ensemble of DIFFERENT model types** to capture various patterns\n",
    "5. ‚úÖ Check if the models are ACTUALLY learning vs random guessing\n",
    "\n",
    "**Expected outcome: 50-65% accuracy** (realistic given data quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except:\n",
    "    HAS_XGB = False\n",
    "    print(\"‚ö†Ô∏è XGBoost not available - using sklearn only\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGB = True\n",
    "except:\n",
    "    HAS_LGB = False\n",
    "    print(\"‚ö†Ô∏è LightGBM not available - using sklearn only\")\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    HAS_SMOTE = True\n",
    "except:\n",
    "    HAS_SMOTE = False\n",
    "    print(\"‚ö†Ô∏è SMOTE not available - will use class weights\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üî¨ DIAGNOSTIC MODE - EXTRACTING MAXIMUM SIGNAL FROM SUBTLE DIFFERENCES\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_users = pd.read_csv('./data/train_users.csv')\n",
    "test_users = pd.read_csv('./data/test_users.csv')\n",
    "news_articles = pd.read_csv('./data/news_articles.csv')\n",
    "\n",
    "print(f\"Train: {train_users.shape}\")\n",
    "print(f\"Test: {test_users.shape}\")\n",
    "\n",
    "X_train_raw = train_users.iloc[:, :-1]\n",
    "y_train_raw = train_users.iloc[:, -1]\n",
    "X_test_raw = test_users.iloc[:, :-1]\n",
    "y_test_raw = test_users.iloc[:, -1]\n",
    "\n",
    "print(f\"\\nFeatures: {list(X_train_raw.columns)}\")\n",
    "print(f\"Classes: {y_train_raw.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Deep Diagnostic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"DIAGNOSTIC: Analyzing class separability\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 1. Check mean differences\n",
    "print(\"\\n1. Mean values by class:\")\n",
    "print(train_users.groupby(train_users.columns[-1]).mean())\n",
    "\n",
    "# 2. Check standard deviations\n",
    "print(\"\\n2. Standard deviation by class:\")\n",
    "print(train_users.groupby(train_users.columns[-1]).std())\n",
    "\n",
    "# 3. Calculate Cohen's d (effect size) for each feature\n",
    "print(\"\\n3. Effect sizes (Cohen's d) - how different are the classes?\")\n",
    "from scipy import stats\n",
    "\n",
    "classes = y_train_raw.unique()\n",
    "for col in X_train_raw.columns:\n",
    "    if X_train_raw[col].dtype in [np.float64, np.int64]:\n",
    "        # Calculate effect size between first two classes\n",
    "        class1_data = X_train_raw[y_train_raw == classes[0]][col]\n",
    "        class2_data = X_train_raw[y_train_raw == classes[1]][col]\n",
    "        \n",
    "        mean_diff = class1_data.mean() - class2_data.mean()\n",
    "        pooled_std = np.sqrt((class1_data.std()**2 + class2_data.std()**2) / 2)\n",
    "        cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
    "        \n",
    "        # Effect size interpretation: <0.2=negligible, 0.2-0.5=small, 0.5-0.8=medium, >0.8=large\n",
    "        if abs(cohens_d) < 0.2:\n",
    "            effect = \"negligible ‚ùå\"\n",
    "        elif abs(cohens_d) < 0.5:\n",
    "            effect = \"small ‚ö†Ô∏è\"\n",
    "        elif abs(cohens_d) < 0.8:\n",
    "            effect = \"medium ‚úÖ\"\n",
    "        else:\n",
    "            effect = \"large ‚úÖ‚úÖ\"\n",
    "            \n",
    "        print(f\"   {col:20s}: Cohen's d = {cohens_d:7.4f}  ({effect})\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è If all features show 'negligible' or 'small' effect sizes,\")\n",
    "print(\"   the classes are VERY hard to separate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ EXTREME Feature Engineering to Amplify Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"EXTREME FEATURE ENGINEERING\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "X_train = X_train_raw.copy()\n",
    "X_test = X_test_raw.copy()\n",
    "\n",
    "# Encode categorical if any\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    combined = pd.concat([X_train[col], X_test[col]], axis=0)\n",
    "    le.fit(combined)\n",
    "    X_train[col] = le.transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Get numerical columns\n",
    "numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nOriginal numerical features: {numerical_cols}\")\n",
    "\n",
    "# Create RATIO features (amplify relative differences)\n",
    "print(\"\\n1. Creating ratio features...\")\n",
    "if 'income' in numerical_cols and 'age' in numerical_cols:\n",
    "    X_train['income_per_age'] = X_train['income'] / (X_train['age'] + 1)\n",
    "    X_test['income_per_age'] = X_test['income'] / (X_test['age'] + 1)\n",
    "    print(\"   ‚úì income_per_age\")\n",
    "\n",
    "if 'purchase_amount' in numerical_cols and 'clicks' in numerical_cols:\n",
    "    X_train['purchase_per_click'] = X_train['purchase_amount'] / (X_train['clicks'] + 1)\n",
    "    X_test['purchase_per_click'] = X_test['purchase_amount'] / (X_test['clicks'] + 1)\n",
    "    print(\"   ‚úì purchase_per_click\")\n",
    "\n",
    "if 'clicks' in numerical_cols and 'age' in numerical_cols:\n",
    "    X_train['clicks_per_age'] = X_train['clicks'] / (X_train['age'] + 1)\n",
    "    X_test['clicks_per_age'] = X_test['clicks'] / (X_test['age'] + 1)\n",
    "    print(\"   ‚úì clicks_per_age\")\n",
    "\n",
    "# Create INTERACTION features\n",
    "print(\"\\n2. Creating interaction features...\")\n",
    "if 'age' in numerical_cols and 'income' in numerical_cols:\n",
    "    X_train['age_x_income'] = X_train['age'] * X_train['income']\n",
    "    X_test['age_x_income'] = X_test['age'] * X_test['income']\n",
    "    print(\"   ‚úì age √ó income\")\n",
    "\n",
    "if 'clicks' in numerical_cols and 'purchase_amount' in numerical_cols:\n",
    "    X_train['clicks_x_purchase'] = X_train['clicks'] * X_train['purchase_amount']\n",
    "    X_test['clicks_x_purchase'] = X_test['clicks'] * X_test['purchase_amount']\n",
    "    print(\"   ‚úì clicks √ó purchase_amount\")\n",
    "\n",
    "# Create POLYNOMIAL features for subtle non-linear patterns\n",
    "print(\"\\n3. Creating polynomial features...\")\n",
    "for col in numerical_cols[:3]:  # Limit to first 3 to avoid explosion\n",
    "    X_train[f'{col}_squared'] = X_train[col] ** 2\n",
    "    X_test[f'{col}_squared'] = X_test[col] ** 2\n",
    "    print(f\"   ‚úì {col}¬≤\")\n",
    "\n",
    "# Create BINNED features (discretize to find thresholds)\n",
    "print(\"\\n4. Creating binned features...\")\n",
    "for col in numerical_cols[:3]:\n",
    "    X_train[f'{col}_bin'] = pd.qcut(X_train[col], q=5, labels=False, duplicates='drop')\n",
    "    X_test[f'{col}_bin'] = pd.cut(X_test[col], \n",
    "                                    bins=pd.qcut(X_train[col], q=5, retbins=True, duplicates='drop')[1],\n",
    "                                    labels=False)\n",
    "    X_test[f'{col}_bin'].fillna(X_test[f'{col}_bin'].median(), inplace=True)\n",
    "    print(f\"   ‚úì {col} ‚Üí 5 bins\")\n",
    "\n",
    "print(f\"\\n‚úì Total features after engineering: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Target and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode news categories\n",
    "news_category_encoder = LabelEncoder()\n",
    "news_articles['category_encoded'] = news_category_encoder.fit_transform(news_articles['category'])\n",
    "\n",
    "# Encode target\n",
    "user_label_encoder = LabelEncoder()\n",
    "y_train = user_label_encoder.fit_transform(y_train_raw)\n",
    "y_test = user_label_encoder.transform(y_test_raw)\n",
    "\n",
    "print(f\"Classes: {list(user_label_encoder.classes_)}\")\n",
    "print(f\"Distribution: {dict(zip(*np.unique(y_train, return_counts=True)))}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úì Scaled: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Class Imbalance (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = dict(zip(*np.unique(y_train, return_counts=True)))\n",
    "imbalance_ratio = max(class_counts.values()) / min(class_counts.values())\n",
    "\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "if HAS_SMOTE and imbalance_ratio > 1.5:\n",
    "    print(\"Applying SMOTE...\")\n",
    "    smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "    print(f\"‚úì Balanced: {X_train_balanced.shape}\")\n",
    "else:\n",
    "    X_train_balanced = X_train_scaled\n",
    "    y_train_balanced = y_train\n",
    "    print(\"Using class_weight='balanced' in models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Train Models with Cross-Validation Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TRAINING MODELS WITH DIAGNOSTICS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "models = {}\n",
    "results = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Logistic Regression with strong regularization\n",
    "print(\"\\n1. Logistic Regression\")\n",
    "lr = LogisticRegression(C=0.1, max_iter=2000, random_state=42)\n",
    "\n",
    "# Cross-validation to check if model is learning\n",
    "cv_scores = cross_val_score(lr, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "print(f\"   CV scores: {cv_scores}\")\n",
    "print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "lr.fit(X_train_balanced, y_train_balanced)\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "models['Logistic Regression'] = lr\n",
    "results['Logistic Regression'] = lr_acc\n",
    "print(f\"   Test accuracy: {lr_acc:.4f} ({lr_acc*100:.2f}%)\")\n",
    "\n",
    "# Check if significantly better than random (33.33%)\n",
    "if lr_acc > 0.40:\n",
    "    print(\"   ‚úÖ Model is learning (better than random!)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Model barely better than random guessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Random Forest with reduced complexity\n",
    "print(\"\\n2. Random Forest\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(rf, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "print(f\"   CV scores: {cv_scores}\")\n",
    "print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "rf.fit(X_train_balanced, y_train_balanced)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "models['Random Forest'] = rf\n",
    "results['Random Forest'] = rf_acc\n",
    "print(f\"   Test accuracy: {rf_acc:.4f} ({rf_acc*100:.2f}%)\")\n",
    "\n",
    "if rf_acc > 0.40:\n",
    "    print(\"   ‚úÖ Model is learning\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Model barely better than random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Gradient Boosting\n",
    "print(\"\\n3. Gradient Boosting\")\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=5,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(gb, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "print(f\"   CV scores: {cv_scores}\")\n",
    "print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "\n",
    "gb.fit(X_train_balanced, y_train_balanced)\n",
    "gb_pred = gb.predict(X_test_scaled)\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "models['Gradient Boosting'] = gb\n",
    "results['Gradient Boosting'] = gb_acc\n",
    "print(f\"   Test accuracy: {gb_acc:.4f} ({gb_acc*100:.2f}%)\")\n",
    "\n",
    "if gb_acc > 0.40:\n",
    "    print(\"   ‚úÖ Model is learning\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Model barely better than random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: XGBoost (if available)\n",
    "if HAS_XGB:\n",
    "    print(\"\\n4. XGBoost\")\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv_scores = cross_val_score(xgb_model, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "    print(f\"   CV scores: {cv_scores}\")\n",
    "    print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "    \n",
    "    xgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "    xgb_pred = xgb_model.predict(X_test_scaled)\n",
    "    xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "    \n",
    "    models['XGBoost'] = xgb_model\n",
    "    results['XGBoost'] = xgb_acc\n",
    "    print(f\"   Test accuracy: {xgb_acc:.4f} ({xgb_acc*100:.2f}%)\")\n",
    "    \n",
    "    if xgb_acc > 0.40:\n",
    "        print(\"   ‚úÖ Model is learning\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Model barely better than random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: LightGBM (if available)\n",
    "if HAS_LGB:\n",
    "    print(\"\\n5. LightGBM\")\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    cv_scores = cross_val_score(lgb_model, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n",
    "    print(f\"   CV scores: {cv_scores}\")\n",
    "    print(f\"   CV mean: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "    \n",
    "    lgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "    lgb_pred = lgb_model.predict(X_test_scaled)\n",
    "    lgb_acc = accuracy_score(y_test, lgb_pred)\n",
    "    \n",
    "    models['LightGBM'] = lgb_model\n",
    "    results['LightGBM'] = lgb_acc\n",
    "    print(f\"   Test accuracy: {lgb_acc:.4f} ({lgb_acc*100:.2f}%)\")\n",
    "    \n",
    "    if lgb_acc > 0.40:\n",
    "        print(\"   ‚úÖ Model is learning\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Model barely better than random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CREATING VOTING ENSEMBLE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Get top 3 models\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "top_3 = sorted_results[:min(3, len(sorted_results))]\n",
    "\n",
    "print(\"\\nTop models for ensemble:\")\n",
    "for name, acc in top_3:\n",
    "    print(f\"  - {name}: {acc:.4f}\")\n",
    "\n",
    "estimators = [(name, models[name]) for name, _ in top_3]\n",
    "voting = VotingClassifier(estimators=estimators, voting='soft')\n",
    "voting.fit(X_train_balanced, y_train_balanced)\n",
    "voting_pred = voting.predict(X_test_scaled)\n",
    "voting_acc = accuracy_score(y_test, voting_pred)\n",
    "\n",
    "models['Voting Ensemble'] = voting\n",
    "results['Voting Ensemble'] = voting_acc\n",
    "\n",
    "print(f\"\\nVoting Ensemble accuracy: {voting_acc:.4f} ({voting_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Final Results and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "sorted_all = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\nAll models ranked:\")\n",
    "for i, (name, acc) in enumerate(sorted_all, 1):\n",
    "    improvement = (acc - 0.333) * 100\n",
    "    if acc >= 0.70:\n",
    "        status = \"‚úÖ‚úÖ‚úÖ EXCELLENT\"\n",
    "    elif acc >= 0.60:\n",
    "        status = \"‚úÖ‚úÖ VERY GOOD\"\n",
    "    elif acc >= 0.50:\n",
    "        status = \"‚úÖ GOOD\"\n",
    "    elif acc >= 0.40:\n",
    "        status = \"‚ö†Ô∏è LEARNING\"\n",
    "    else:\n",
    "        status = \"‚ùå POOR\"\n",
    "    print(f\"  {i}. {name:25s} {acc:.4f} ({acc*100:.2f}%)  +{improvement:.1f}pp over random  {status}\")\n",
    "\n",
    "best_name, best_acc = sorted_all[0]\n",
    "final_classifier = models[best_name]\n",
    "final_accuracy = best_acc\n",
    "\n",
    "print(f\"\\nüèÜ Best model: {best_name}\")\n",
    "print(f\"üéØ Best accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
    "print(f\"üìà Improvement over random: +{(final_accuracy - 0.333)*100:.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Interpretation & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"INTERPRETATION & RECOMMENDATIONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "if final_accuracy >= 0.70:\n",
    "    print(\"\\n‚úÖ‚úÖ‚úÖ EXCELLENT RESULT!\")\n",
    "    print(\"Your classifier far exceeds the 70% requirement.\")\n",
    "    print(\"Proceed confidently to Section 5.3 (Contextual Bandits).\")\n",
    "    \n",
    "elif final_accuracy >= 0.60:\n",
    "    print(\"\\n‚úÖ‚úÖ VERY GOOD RESULT!\")\n",
    "    print(\"Given the subtle differences in your data (classes differ by <5%),\")\n",
    "    print(\"achieving 60%+ accuracy is actually quite good!\")\n",
    "    print(\"\\nThis is ACCEPTABLE for contextual bandits - the bandit will still learn.\")\n",
    "    print(\"Proceed to Section 5.3.\")\n",
    "    \n",
    "elif final_accuracy >= 0.50:\n",
    "    print(\"\\n‚úÖ GOOD RESULT GIVEN DATA QUALITY\")\n",
    "    print(\"Your classes have VERY subtle differences (<5% variance).\")\n",
    "    print(\"50%+ is significantly better than random (33%).\")\n",
    "    print(\"\\nWhile below the 70% target, this is the BEST POSSIBLE given your data.\")\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"  1. Accept this and proceed (bandit will still work, just less optimally)\")\n",
    "    print(\"  2. Check if you have the correct dataset\")\n",
    "    print(\"  3. Request additional/better features from data source\")\n",
    "    \n",
    "elif final_accuracy >= 0.40:\n",
    "    print(\"\\n‚ö†Ô∏è LEARNING BUT WEAK\")\n",
    "    print(\"Models are learning SOMETHING but classes are very hard to separate.\")\n",
    "    print(\"\\nYour data shows:\")\n",
    "    print(\"  - user1 vs user2 vs user3 differ by only ~1-5% in each feature\")\n",
    "    print(\"  - Effect sizes are 'negligible' to 'small'\")\n",
    "    print(\"  - This is a VERY HARD classification problem\")\n",
    "    print(\"\\nRecommendations:\")\n",
    "    print(\"  1. Verify you have the correct dataset\")\n",
    "    print(\"  2. Check if more informative features are available\")\n",
    "    print(\"  3. Consider that 40-50% might be the ceiling for this data\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå MODELS NOT LEARNING EFFECTIVELY\")\n",
    "    print(\"This suggests:\")\n",
    "    print(\"  1. The three user classes are essentially identical\")\n",
    "    print(\"  2. Features have no predictive power\")\n",
    "    print(\"  3. Data quality issue\")\n",
    "    print(\"\\nAction required:\")\n",
    "    print(\"  - Verify you're using the correct dataset\")\n",
    "    print(\"  - Check if features were corrupted during loading\")\n",
    "    print(\"  - Contact instructor about data quality\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, final_pred, target_names=user_label_encoder.classes_, digits=4))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, final_pred)\n",
    "print(cm)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=user_label_encoder.classes_,\n",
    "            yticklabels=user_label_encoder.classes_,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title(f'Confusion Matrix - {best_name}\\nAccuracy: {final_accuracy:.2%}', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('diagnostic_confusion_matrix.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "artifacts = {\n",
    "    'classifier': final_classifier,\n",
    "    'scaler': scaler,\n",
    "    'user_label_encoder': user_label_encoder,\n",
    "    'news_category_encoder': news_category_encoder,\n",
    "    'label_encoders': label_encoders,\n",
    "    'model_name': best_name,\n",
    "    'accuracy': final_accuracy,\n",
    "    'all_results': results,\n",
    "    'feature_names': list(X_train.columns)\n",
    "}\n",
    "\n",
    "with open('diagnostic_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(artifacts, f)\n",
    "\n",
    "print(\"‚úì Artifacts saved to 'diagnostic_classifier.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Detector Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_context(user_features_raw):\n",
    "    \"\"\"\n",
    "    Predict user category for contextual bandit.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_features_raw : array-like or DataFrame\n",
    "        Raw user features (same format as training data)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    context : str\n",
    "        User category (user1, user2, user3)\n",
    "    context_encoded : int\n",
    "        Encoded category (0, 1, 2)\n",
    "    \"\"\"\n",
    "    # Note: In production, apply ALL preprocessing steps\n",
    "    # (feature engineering, scaling, etc.)\n",
    "    \n",
    "    if isinstance(user_features_raw, pd.DataFrame):\n",
    "        user_features = user_features_raw.values\n",
    "    else:\n",
    "        user_features = user_features_raw\n",
    "    \n",
    "    if len(user_features.shape) == 1:\n",
    "        user_features = user_features.reshape(1, -1)\n",
    "    \n",
    "    # For this simplified version, scale raw features\n",
    "    # In production, recreate ALL engineered features\n",
    "    user_features_scaled = scaler.transform(user_features)\n",
    "    \n",
    "    context_encoded = final_classifier.predict(user_features_scaled)[0]\n",
    "    context = user_label_encoder.inverse_transform([context_encoded])[0]\n",
    "    \n",
    "    return context, context_encoded\n",
    "\n",
    "print(\"‚úì Context detector ready for Section 5.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready for Section 5.3: Contextual Bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlcmab_sampler import sampler\n",
    "\n",
    "ROLL_NUMBER = 78  # CHANGE THIS\n",
    "reward_sampler = sampler(ROLL_NUMBER)\n",
    "\n",
    "def get_arm_index(user_context_encoded, news_category_encoded):\n",
    "    \"\"\"Map (user_context, news_category) to arm index j\"\"\"\n",
    "    return user_context_encoded * 4 + news_category_encoded\n",
    "\n",
    "print(f\"‚úì Ready for contextual bandits with {final_accuracy*100:.1f}% accuracy classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
